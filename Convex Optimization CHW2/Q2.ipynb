{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.6.0                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jan 04 03:16:41 AM: Your problem has 50 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) Jan 04 03:16:41 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jan 04 03:16:41 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jan 04 03:16:41 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Jan 04 03:16:41 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:16:41 AM: Compiling problem (target solver=CLARABEL).\n",
      "(CVXPY) Jan 04 03:16:41 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n",
      "(CVXPY) Jan 04 03:16:41 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jan 04 03:16:41 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jan 04 03:16:41 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jan 04 03:16:41 AM: Applying reduction CLARABEL\n",
      "(CVXPY) Jan 04 03:16:41 AM: Finished problem compilation (took 1.297e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:16:41 AM: Invoking solver CLARABEL  to obtain a solution.\n",
      "-------------------------------------------------------------\n",
      "           Clarabel.rs v0.9.0  -  Clever Acronym                \n",
      "\n",
      "                   (c) Paul Goulart                          \n",
      "                University of Oxford, 2022                   \n",
      "-------------------------------------------------------------\n",
      "\n",
      "problem:\n",
      "  variables     = 101\n",
      "  constraints   = 201\n",
      "  nnz(P)        = 1\n",
      "  nnz(A)        = 5201\n",
      "  cones (total) = 2\n",
      "    : Nonnegative = 1,  numel = 100\n",
      "    : SecondOrder = 1,  numel = 101\n",
      "\n",
      "settings:\n",
      "  linear algebra: direct / qdldl, precision: 64 bit\n",
      "  max iter = 200, time limit = Inf,  max step = 0.990\n",
      "  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n",
      "  static reg : on, ϵ1 = 1.0e-8, ϵ2 = 4.9e-32\n",
      "  dynamic reg: on, ϵ = 1.0e-13, δ = 2.0e-7\n",
      "  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n",
      "               max iter = 10, stop ratio = 5.0\n",
      "  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n",
      "               max iter = 10\n",
      "\n",
      "iter    pcost        dcost       gap       pres      dres      k/t        μ       step      \n",
      "---------------------------------------------------------------------------------------------\n",
      "  0  -2.5000e+00  +2.5247e+00  2.01e+00  9.59e-01  1.20e+00  1.00e+00  3.33e+01   ------   \n",
      "  1  +1.6895e+03  -1.0875e+03  2.55e+00  5.36e-01  6.31e-01  7.15e+02  2.32e+01  9.90e-01  \n",
      "  2  +7.5592e+02  -1.4507e+02  6.21e+00  6.33e-02  1.10e-01  2.40e+03  3.48e+00  9.90e-01  \n",
      "  3  +2.5740e+02  +1.9846e+01  1.20e+01  7.25e-03  1.38e-02  7.22e+02  5.97e-01  9.90e-01  \n",
      "  4  +3.8046e+01  +2.3041e+01  6.51e-01  4.11e-03  2.33e-03  1.28e+02  8.60e-02  9.18e-01  \n",
      "  5  +2.4599e+01  +2.3205e+01  6.01e-02  5.00e-04  2.18e-04  1.19e+01  8.33e-03  9.03e-01  \n",
      "  6  +2.3874e+01  +2.3614e+01  1.10e-02  7.47e-05  3.24e-05  1.25e+00  1.24e-03  8.97e-01  \n",
      "  7  +2.3803e+01  +2.3710e+01  3.94e-03  1.86e-05  8.05e-06  2.21e-02  3.09e-04  9.90e-01  \n",
      "  8  +2.3750e+01  +2.3738e+01  5.20e-04  2.45e-06  1.06e-06  2.86e-03  4.08e-05  8.73e-01  \n",
      "  9  +2.3749e+01  +2.3738e+01  4.64e-04  2.18e-06  9.46e-07  2.31e-03  3.63e-05  2.55e-01  \n",
      " 10  +2.3744e+01  +2.3742e+01  1.21e-04  5.70e-07  2.47e-07  5.55e-04  9.48e-06  7.80e-01  \n",
      " 11  +2.3744e+01  +2.3742e+01  9.48e-05  4.44e-07  1.92e-07  3.86e-04  7.39e-06  3.99e-01  \n",
      " 12  +2.3743e+01  +2.3743e+01  1.59e-05  7.46e-08  3.23e-08  6.28e-05  1.24e-06  8.45e-01  \n",
      " 13  +2.3743e+01  +2.3743e+01  5.82e-06  2.72e-08  1.18e-08  2.00e-05  4.53e-07  7.57e-01  \n",
      " 14  +2.3743e+01  +2.3743e+01  1.54e-06  7.21e-09  3.13e-09  5.11e-06  1.20e-07  7.66e-01  \n",
      " 15  +2.3743e+01  +2.3743e+01  4.95e-07  2.31e-09  1.00e-09  1.46e-06  3.84e-08  8.10e-01  \n",
      " 16  +2.3743e+01  +2.3743e+01  1.26e-07  5.89e-10  2.55e-10  3.62e-07  9.80e-09  7.82e-01  \n",
      " 17  +2.3743e+01  +2.3743e+01  2.37e-08  1.11e-10  4.79e-11  6.27e-08  1.84e-09  9.05e-01  \n",
      " 18  +2.3743e+01  +2.3743e+01  4.95e-09  1.65e-08  1.00e-11  1.30e-08  3.84e-10  8.14e-01  \n",
      "---------------------------------------------------------------------------------------------\n",
      "Terminated with status = AlmostSolved\n",
      "solve time = 11.1752ms\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:16:41 AM: Problem status: optimal_inaccurate\n",
      "(CVXPY) Jan 04 03:16:41 AM: Optimal value: 2.374e+01\n",
      "(CVXPY) Jan 04 03:16:41 AM: Compilation took 1.297e-02 seconds\n",
      "(CVXPY) Jan 04 03:16:41 AM: Solver (including time spent in interface) took 1.396e-02 seconds\n",
      "CVXPY solution time: 0.0359 seconds\n",
      "Proximal Gradient solution time (stepsize=0.01): 0.0229 seconds\n",
      "Proximal Gradient solution time (stepsize=0.05): 0.0209 seconds\n",
      "Proximal Gradient solution time (stepsize=0.1): 0.0199 seconds\n",
      "ADMM solution time (rho=0.1): 0.0140 seconds\n",
      "ADMM solution time (rho=1): 0.0020 seconds\n",
      "ADMM solution time (rho=10): 0.0010 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_4880\\3467047169.py:32: RuntimeWarning: overflow encountered in matmul\n",
      "  grad = A.T @ (A @ x - b)\n",
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_4880\\3467047169.py:32: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad = A.T @ (A @ x - b)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import cvxpy as cp\n",
    "import time\n",
    "\n",
    "# Problem setup for LASSO\n",
    "np.random.seed(0)\n",
    "m, n = 100, 50  # Changeable dimensions for testing\n",
    "A = np.random.randn(m, n)\n",
    "b = np.random.randn(m)\n",
    "gamma = 0.1\n",
    "\n",
    "# Part 1: Solve using CVXPY\n",
    "start_time = time.time()\n",
    "x = cp.Variable(n)\n",
    "loss = (1/2) * cp.norm2(A @ x - b)**2 + gamma * cp.norm1(x)\n",
    "problem = cp.Problem(cp.Minimize(loss))\n",
    "problem.solve(verbose=True)\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"CVXPY solution time: {cvxpy_time:.4f} seconds\")\n",
    "\n",
    "# Part 2: Proximal Gradient Algorithm\n",
    "\n",
    "def soft_thresholding(y, lambd):\n",
    "    return np.sign(y) * np.maximum(np.abs(y) - lambd, 0)\n",
    "\n",
    "\n",
    "def proximal_gradient(A, b, gamma, stepsize, max_iters=1000, tol=1e-6):\n",
    "    n = A.shape[1]\n",
    "    x = np.zeros(n)\n",
    "    for k in range(max_iters):\n",
    "        grad = A.T @ (A @ x - b)\n",
    "        x_new = soft_thresholding(x - stepsize * grad, stepsize * gamma)\n",
    "        if np.linalg.norm(x_new - x, ord=2) < tol:\n",
    "            break\n",
    "        x = x_new\n",
    "    return x\n",
    "\n",
    "stepsizes = [0.01, 0.05, 0.1]\n",
    "for stepsize in stepsizes:\n",
    "    start_time = time.time()\n",
    "    x_pg = proximal_gradient(A, b, gamma, stepsize)\n",
    "    pg_time = time.time() - start_time\n",
    "    print(f\"Proximal Gradient solution time (stepsize={stepsize}): {pg_time:.4f} seconds\")\n",
    "\n",
    "# Part 3: ADMM Algorithm\n",
    "\n",
    "def admm_lasso(A, b, gamma, rho, max_iters=1000, tol=1e-6):\n",
    "    m, n = A.shape\n",
    "    x = np.zeros(n)\n",
    "    y = np.zeros(n)\n",
    "    mu = np.zeros(n)\n",
    "    ATA = A.T @ A\n",
    "    ATb = A.T @ b\n",
    "    inv_matrix = la.inv(rho * np.eye(n) + ATA)\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        x = inv_matrix @ (rho * y - mu + ATb)\n",
    "        y = soft_thresholding(x + mu / rho, gamma / rho)\n",
    "        mu += rho * (x - y)\n",
    "        if np.linalg.norm(x - y, ord=2) < tol:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "rhos = [0.1, 1, 10]\n",
    "for rho in rhos:\n",
    "    start_time = time.time()\n",
    "    x_admm = admm_lasso(A, b, gamma, rho)\n",
    "    admm_time = time.time() - start_time\n",
    "    print(f\"ADMM solution time (rho={rho}): {admm_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.6.0                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jan 04 04:59:21 AM: Your problem has 50 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) Jan 04 04:59:21 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jan 04 04:59:21 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jan 04 04:59:21 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Jan 04 04:59:21 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 04:59:21 AM: Compiling problem (target solver=CLARABEL).\n",
      "(CVXPY) Jan 04 04:59:21 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n",
      "(CVXPY) Jan 04 04:59:21 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jan 04 04:59:21 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jan 04 04:59:21 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jan 04 04:59:21 AM: Applying reduction CLARABEL\n",
      "(CVXPY) Jan 04 04:59:21 AM: Finished problem compilation (took 1.297e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 04:59:21 AM: Invoking solver CLARABEL  to obtain a solution.\n",
      "-------------------------------------------------------------\n",
      "           Clarabel.rs v0.9.0  -  Clever Acronym                \n",
      "\n",
      "                   (c) Paul Goulart                          \n",
      "                University of Oxford, 2022                   \n",
      "-------------------------------------------------------------\n",
      "\n",
      "problem:\n",
      "  variables     = 101\n",
      "  constraints   = 201\n",
      "  nnz(P)        = 1\n",
      "  nnz(A)        = 5201\n",
      "  cones (total) = 2\n",
      "    : Nonnegative = 1,  numel = 100\n",
      "    : SecondOrder = 1,  numel = 101\n",
      "\n",
      "settings:\n",
      "  linear algebra: direct / qdldl, precision: 64 bit\n",
      "  max iter = 200, time limit = Inf,  max step = 0.990\n",
      "  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n",
      "  static reg : on, ϵ1 = 1.0e-8, ϵ2 = 4.9e-32\n",
      "  dynamic reg: on, ϵ = 1.0e-13, δ = 2.0e-7\n",
      "  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n",
      "               max iter = 10, stop ratio = 5.0\n",
      "  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n",
      "               max iter = 10\n",
      "\n",
      "iter    pcost        dcost       gap       pres      dres      k/t        μ       step      \n",
      "---------------------------------------------------------------------------------------------\n",
      "  0  -2.5000e+00  +2.2937e+00  2.09e+00  1.02e+00  1.35e+00  1.00e+00  2.90e+01   ------   \n",
      "  1  -2.7926e-01  +4.6522e-01  7.44e-01  5.69e-01  6.31e-01  4.76e+00  1.98e+01  9.90e-01  \n",
      "  2  +2.9158e-01  +4.4635e-01  1.55e-01  9.03e-02  9.76e-02  1.46e+00  4.56e+00  8.76e-01  \n",
      "  3  +4.7214e-01  +4.8631e-01  1.42e-02  1.36e-02  1.52e-02  1.92e-01  8.35e-01  8.61e-01  \n",
      "  4  +4.8420e-01  +4.8248e-01  1.73e-03  7.88e-04  8.95e-04  9.32e-03  7.17e-02  9.74e-01  \n",
      "  5  +4.8371e-01  +4.8324e-01  4.71e-04  1.64e-04  1.87e-04  1.31e-03  1.53e-02  8.72e-01  \n",
      "  6  +4.8338e-01  +4.8325e-01  1.27e-04  3.72e-05  4.23e-05  2.40e-04  3.56e-03  8.33e-01  \n",
      "  7  +4.8332e-01  +4.8328e-01  4.44e-05  1.20e-05  1.37e-05  4.62e-05  1.15e-03  8.34e-01  \n",
      "  8  +4.8328e-01  +4.8327e-01  6.09e-06  1.52e-06  1.73e-06  4.40e-06  1.48e-04  9.19e-01  \n",
      "  9  +4.8328e-01  +4.8328e-01  7.89e-07  1.92e-07  2.18e-07  3.68e-07  1.87e-05  9.41e-01  \n",
      " 10  +4.8328e-01  +4.8328e-01  1.06e-07  2.50e-08  2.84e-08  4.29e-08  2.46e-06  9.02e-01  \n",
      " 11  +4.8328e-01  +4.8328e-01  3.48e-09  8.18e-10  9.30e-10  1.23e-09  8.04e-08  9.78e-01  \n",
      "---------------------------------------------------------------------------------------------\n",
      "Terminated with status = Solved\n",
      "solve time = 7.092ms\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 04:59:21 AM: Problem status: optimal\n",
      "(CVXPY) Jan 04 04:59:21 AM: Optimal value: 4.833e-01\n",
      "(CVXPY) Jan 04 04:59:21 AM: Compilation took 1.297e-02 seconds\n",
      "(CVXPY) Jan 04 04:59:21 AM: Solver (including time spent in interface) took 8.976e-03 seconds\n",
      "CVXPY solution time: 0.0299 seconds\n",
      "Proximal Gradient solution time (stepsize=0.01): 0.0379 seconds\n",
      "Proximal Gradient solution time (stepsize=0.05): 0.0205 seconds\n",
      "Proximal Gradient solution time (stepsize=0.1): 0.0110 seconds\n",
      "ADMM solution time (rho=0.1): 0.0040 seconds\n",
      "ADMM solution time (rho=1): 0.0020 seconds\n",
      "ADMM solution time (rho=10): 0.0060 seconds\n"
     ]
    }
   ],
   "source": [
    "#Final\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import cvxpy as cp\n",
    "import time\n",
    "\n",
    "# Problem setup for LASSO\n",
    "np.random.seed(0)\n",
    "m, n = 100, 50  # Changeable dimensions for testing\n",
    "A = np.random.randn(m, n)\n",
    "b = np.random.randn(m)\n",
    "gamma = 0.1\n",
    "\n",
    "# Normalize A and b to prevent overflow issues\n",
    "A = A / np.linalg.norm(A, ord=2)\n",
    "b = b / np.linalg.norm(b, ord=2)\n",
    "\n",
    "# Part 1: Solve using CVXPY\n",
    "start_time = time.time()\n",
    "x = cp.Variable(n)\n",
    "loss = (1/2) * cp.norm2(A @ x - b)**2 + gamma * cp.norm1(x)\n",
    "problem = cp.Problem(cp.Minimize(loss))\n",
    "problem.solve(verbose=True)\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"CVXPY solution time: {cvxpy_time:.4f} seconds\")\n",
    "\n",
    "# Part 2: Proximal Gradient Algorithm\n",
    "\n",
    "def soft_thresholding(y, lambd):\n",
    "    return np.sign(y) * np.maximum(np.abs(y) - lambd, 0)\n",
    "\n",
    "\n",
    "def proximal_gradient(A, b, gamma, stepsize, max_iters=1000, tol=1e-6):\n",
    "    n = A.shape[1]\n",
    "    x = np.zeros(n)\n",
    "    L = np.linalg.norm(A.T @ A, ord=2)\n",
    "    stepsize = min(stepsize, 1 / (2 * L))\n",
    "    for k in range(max_iters):\n",
    "        grad = A.T @ (A @ x - b)\n",
    "        x_new = soft_thresholding(x - stepsize * grad, stepsize * gamma)\n",
    "        if np.any(np.isnan(x_new)) or np.any(np.isinf(x_new)):\n",
    "            print(\"Numerical instability detected. Stopping iteration.\")\n",
    "            break\n",
    "        if np.linalg.norm(x_new - x, ord=2) < tol:\n",
    "            break\n",
    "        x = x_new\n",
    "    return x\n",
    "\n",
    "stepsizes = [0.01, 0.05, 0.1]\n",
    "for stepsize in stepsizes:\n",
    "    start_time = time.time()\n",
    "    x_pg = proximal_gradient(A, b, gamma, stepsize)\n",
    "    pg_time = time.time() - start_time\n",
    "    print(f\"Proximal Gradient solution time (stepsize={stepsize}): {pg_time:.4f} seconds\")\n",
    "\n",
    "# Part 3: ADMM Algorithm\n",
    "\n",
    "def admm_lasso(A, b, gamma, rho, max_iters=1000, tol=1e-6):\n",
    "    m, n = A.shape\n",
    "    x = np.zeros(n)\n",
    "    y = np.zeros(n)\n",
    "    mu = np.zeros(n)\n",
    "    ATA = A.T @ A\n",
    "    ATb = A.T @ b\n",
    "    inv_matrix = la.inv(rho * np.eye(n) + ATA)\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        x = inv_matrix @ (rho * y - mu + ATb)\n",
    "        y = soft_thresholding(x + mu / rho, gamma / rho)\n",
    "        mu += rho * (x - y)\n",
    "        if np.any(np.isnan(x)) or np.any(np.isinf(x)):\n",
    "            print(\"Numerical instability detected. Stopping iteration.\")\n",
    "            break\n",
    "        if np.linalg.norm(x - y, ord=2) < tol:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "rhos = [0.1, 1, 10]\n",
    "for rho in rhos:\n",
    "    start_time = time.time()\n",
    "    x_admm = admm_lasso(A, b, gamma, rho)\n",
    "    admm_time = time.time() - start_time\n",
    "    print(f\"ADMM solution time (rho={rho}): {admm_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Password Please\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1481: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: (50, 20), Optimal Value: 13.2624, Computation Time: 0.0120 seconds\n",
      "Dimension: (100, 50), Optimal Value: 23.7428, Computation Time: 0.0199 seconds\n",
      "Dimension: (200, 100), Optimal Value: 56.0480, Computation Time: 0.0559 seconds\n",
      "Dimension: (500, 200), Optimal Value: 145.6908, Computation Time: 0.4378 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "gamma = 0.1  # Regularization parameter\n",
    "dimensions = [(50, 20), (100, 50), (200, 100), (500, 200)]  # Different dimensions for A and b\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for m, n in dimensions:\n",
    "    # Generate random data\n",
    "    np.random.seed(0)\n",
    "    A = np.random.randn(m, n)\n",
    "    b = np.random.randn(m)\n",
    "    \n",
    "    # Define optimization variable\n",
    "    x = cp.Variable(n)\n",
    "    \n",
    "    # Define the LASSO objective\n",
    "    objective = cp.Minimize(0.5 * cp.norm(A @ x - b, 2)**2 + gamma * cp.norm(x, 1))\n",
    "    \n",
    "    # Solve the problem and measure time\n",
    "    problem = cp.Problem(objective)\n",
    "    start_time = time.time()\n",
    "    problem.solve()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Record results\n",
    "    results.append({\n",
    "        'dimension': (m, n),\n",
    "        'optimal_value': problem.value,\n",
    "        'computation_time': end_time - start_time\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"Dimension: {result['dimension']}, Optimal Value: {result['optimal_value']:.4f}, \"\n",
    "          f\"Computation Time: {result['computation_time']:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_samples  n_features  objective_value  time_taken_sec\n",
      "0        100          50        19.264617        0.016293\n",
      "1        200         100        56.040808        0.033994\n",
      "2        500         200       157.364405        0.248161\n",
      "3       1000         500       229.952553        2.286817\n"
     ]
    }
   ],
   "source": [
    "#Final\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def solve_lasso_cvxpy(n_samples, n_features, gamma=0.1):\n",
    "    # Generate random A and b\n",
    "    np.random.seed(42)\n",
    "    A = np.random.randn(n_samples, n_features)\n",
    "    b = np.random.randn(n_samples)\n",
    "    \n",
    "    # Define the optimization variable\n",
    "    x = cp.Variable(n_features)\n",
    "    \n",
    "    # Define the LASSO objective\n",
    "    objective = cp.Minimize(0.5 * cp.sum_squares(A @ x - b) + gamma * cp.norm1(x))\n",
    "    \n",
    "    # Define and solve the problem\n",
    "    problem = cp.Problem(objective)\n",
    "    start_time = time.time()\n",
    "    problem.solve()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return problem.value, end_time - start_time\n",
    "\n",
    "# Test the function for different matrix dimensions\n",
    "dimensions = [(100, 50), (200, 100), (500, 200), (1000, 500)]\n",
    "gamma = 0.1\n",
    "results = []\n",
    "\n",
    "for n_samples, n_features in dimensions:\n",
    "    value, time_taken = solve_lasso_cvxpy(n_samples, n_features, gamma)\n",
    "    results.append({\n",
    "        \"n_samples\": n_samples,\n",
    "        \"n_features\": n_features,\n",
    "        \"objective_value\": value,\n",
    "        \"time_taken_sec\": time_taken\n",
    "    })\n",
    "\n",
    "# Display the results in a table\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_8056\\234396832.py:30: RuntimeWarning: overflow encountered in matmul\n",
      "  gradient = A.T @ (A @ x - b)  # Gradient of the least squares term\n",
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_8056\\234396832.py:32: RuntimeWarning: invalid value encountered in matmul\n",
      "  obj_value = 0.5 * np.linalg.norm(A @ x_new - b)**2 + gamma * np.linalg.norm(x_new, 1)\n",
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_8056\\234396832.py:30: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradient = A.T @ (A @ x - b)  # Gradient of the least squares term\n",
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_8056\\234396832.py:31: RuntimeWarning: invalid value encountered in subtract\n",
      "  x_new = proximal_operator(x - step_size * gradient, gamma * step_size)  # Proximal update\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>step_size</th>\n",
       "      <th>final_objective_value</th>\n",
       "      <th>iterations</th>\n",
       "      <th>time_taken_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.264617</td>\n",
       "      <td>522</td>\n",
       "      <td>0.020944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>inf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.039894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.039894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>51.082933</td>\n",
       "      <td>397</td>\n",
       "      <td>0.260432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.726218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.646331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>129.783602</td>\n",
       "      <td>115</td>\n",
       "      <td>0.078791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.667897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.744071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_samples  n_features  step_size  final_objective_value  iterations  \\\n",
       "0        100          50      0.001              19.264617         522   \n",
       "1        100          50      0.010                    inf        1000   \n",
       "2        100          50      0.100                    NaN        1000   \n",
       "3        200         100      0.001              51.082933         397   \n",
       "4        200         100      0.010                    NaN        1000   \n",
       "5        200         100      0.100                    NaN        1000   \n",
       "6        500         200      0.001             129.783602         115   \n",
       "7        500         200      0.010                    NaN        1000   \n",
       "8        500         200      0.100                    NaN        1000   \n",
       "\n",
       "   time_taken_sec  \n",
       "0        0.020944  \n",
       "1        0.039894  \n",
       "2        0.039894  \n",
       "3        0.260432  \n",
       "4        0.726218  \n",
       "5        0.646331  \n",
       "6        0.078791  \n",
       "7        0.667897  \n",
       "8        0.744071  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def proximal_operator(x, threshold):\n",
    "    \"\"\"\n",
    "    Soft-thresholding operator for L1 norm.\n",
    "    \"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)\n",
    "\n",
    "def proximal_gradient_lasso(A, b, gamma, step_size, max_iter=1000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Proximal gradient algorithm for solving LASSO problem.\n",
    "    Args:\n",
    "        A (numpy.ndarray): Input matrix (n_samples, n_features).\n",
    "        b (numpy.ndarray): Target vector (n_samples,).\n",
    "        gamma (float): Regularization parameter for L1 norm.\n",
    "        step_size (float): Step size for gradient descent.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "        tol (float): Tolerance for convergence.\n",
    "    Returns:\n",
    "        x (numpy.ndarray): Solution vector (n_features,).\n",
    "        history (list): Objective function values over iterations.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = np.zeros(n_features)  # Initialize x to zero\n",
    "    history = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        gradient = A.T @ (A @ x - b)  # Gradient of the least squares term\n",
    "        x_new = proximal_operator(x - step_size * gradient, gamma * step_size)  # Proximal update\n",
    "        obj_value = 0.5 * np.linalg.norm(A @ x_new - b)**2 + gamma * np.linalg.norm(x_new, 1)\n",
    "        history.append(obj_value)\n",
    "        \n",
    "        if np.linalg.norm(x_new - x) < tol:  # Convergence check\n",
    "            break\n",
    "        \n",
    "        x = x_new\n",
    "\n",
    "    return x, history\n",
    "\n",
    "# Test the proximal gradient algorithm for different dimensions and step sizes\n",
    "np.random.seed(42)\n",
    "dimensions = [(100, 50), (200, 100), (500, 200)]\n",
    "gamma = 0.1\n",
    "step_sizes = [0.001, 0.01, 0.1]\n",
    "results = []\n",
    "\n",
    "for n_samples, n_features in dimensions:\n",
    "    A = np.random.randn(n_samples, n_features)\n",
    "    b = np.random.randn(n_samples)\n",
    "    for step_size in step_sizes:\n",
    "        start_time = time.time()\n",
    "        x, history = proximal_gradient_lasso(A, b, gamma, step_size)\n",
    "        end_time = time.time()\n",
    "        results.append({\n",
    "            \"n_samples\": n_samples,\n",
    "            \"n_features\": n_features,\n",
    "            \"step_size\": step_size,\n",
    "            \"final_objective_value\": history[-1],\n",
    "            \"iterations\": len(history),\n",
    "            \"time_taken_sec\": end_time - start_time\n",
    "        })\n",
    "\n",
    "# Display the results in a table\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.6.0                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jan 04 03:18:29 AM: Your problem has 435 variables, 435 constraints, and 0 parameters.\n",
      "(CVXPY) Jan 04 03:18:29 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jan 04 03:18:29 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jan 04 03:18:29 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Jan 04 03:18:29 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:18:29 AM: Compiling problem (target solver=CLARABEL).\n",
      "(CVXPY) Jan 04 03:18:29 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n",
      "(CVXPY) Jan 04 03:18:29 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jan 04 03:18:29 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jan 04 03:18:29 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jan 04 03:18:29 AM: Applying reduction CLARABEL\n",
      "(CVXPY) Jan 04 03:18:29 AM: Finished problem compilation (took 1.795e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:18:29 AM: Invoking solver CLARABEL  to obtain a solution.\n",
      "-------------------------------------------------------------\n",
      "           Clarabel.rs v0.9.0  -  Clever Acronym                \n",
      "\n",
      "                   (c) Paul Goulart                          \n",
      "                University of Oxford, 2022                   \n",
      "-------------------------------------------------------------\n",
      "\n",
      "problem:\n",
      "  variables     = 466\n",
      "  constraints   = 961\n",
      "  nnz(P)        = 1\n",
      "  nnz(A)        = 13951\n",
      "  cones (total) = 32\n",
      "    : Nonnegative = 1,  numel = 435\n",
      "    : SecondOrder = 1,  numel = 436\n",
      "    : Exponential = 30,  numel = (3,3,3,3,...,3)\n",
      "\n",
      "settings:\n",
      "  linear algebra: direct / qdldl, precision: 64 bit\n",
      "  max iter = 200, time limit = Inf,  max step = 0.990\n",
      "  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n",
      "  static reg : on, ϵ1 = 1.0e-8, ϵ2 = 4.9e-32\n",
      "  dynamic reg: on, ϵ = 1.0e-13, δ = 2.0e-7\n",
      "  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n",
      "               max iter = 10, stop ratio = 5.0\n",
      "  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n",
      "               max iter = 10\n",
      "\n",
      "iter    pcost        dcost       gap       pres      dres      k/t        μ       step      \n",
      "---------------------------------------------------------------------------------------------\n",
      "  0  +0.0000e+00  -7.1508e+01  7.15e+01  9.55e-01  1.53e+01  1.00e+00  1.00e+00   ------   \n",
      "  1  -2.8927e+01  -7.7595e+01  1.68e+00  6.34e-01  7.58e+00  1.00e+00  5.04e-01  7.06e-01  \n",
      "  2  -1.4482e+01  -2.8794e+01  9.88e-01  1.67e-01  1.65e+00  4.40e-01  1.10e-01  7.92e-01  \n",
      "  3  -1.6916e+01  -2.4945e+01  4.75e-01  7.26e-02  1.21e+00  2.07e-01  6.65e-02  5.07e-01  \n",
      "  4  -5.4667e+01  -6.0395e+01  1.05e-01  1.06e-02  1.10e+00  3.10e-01  2.80e-02  8.32e-01  \n",
      "  5  -1.6581e+02  -1.7245e+02  4.01e-02  2.28e-03  6.61e-01  1.04e+00  6.87e-03  7.92e-01  \n",
      "  6  -4.1399e+02  -4.8783e+02  1.78e-01  5.89e-04  1.73e-01  5.46e+00  1.87e-03  7.38e-01  \n",
      "  7  -6.8030e+02  -2.3275e+03  2.42e+00  1.24e-04  2.89e-02  2.39e+01  4.07e-04  7.92e-01  \n",
      "  8  -2.7548e+03  -4.4321e+03  6.09e-01  5.44e-05  1.47e-02  2.18e+01  1.80e-04  6.55e-01  \n",
      "  9  -5.0196e+03  -6.4436e+03  2.84e-01  3.67e-05  1.20e-02  1.86e+01  1.20e-04  6.95e-01  \n",
      " 10  -4.5605e+03  -5.8136e+03  2.75e-01  3.32e-05  1.18e-02  1.58e+01  1.07e-04  3.43e-01  \n",
      " 11  -7.7689e+03  -1.0867e+04  3.99e-01  7.34e-06  3.12e-03  8.52e+00  2.61e-05  8.42e-01  \n",
      " 12  -8.5551e+03  -1.1198e+04  3.09e-01  6.29e-06  2.83e-03  7.63e+00  2.24e-05  3.10e-01  \n",
      " 13  -1.0129e+04  -1.1982e+04  1.83e-01  4.35e-06  2.06e-03  5.41e+00  1.53e-05  5.47e-01  \n",
      " 14  -1.0166e+04  -1.1564e+04  1.38e-01  3.34e-06  1.63e-03  4.23e+00  1.17e-05  5.23e-01  \n",
      " 15  -1.1915e+04  -1.2499e+04  4.90e-02  1.29e-06  6.02e-04  1.57e+00  4.49e-06  7.12e-01  \n",
      " 16  -1.2188e+04  -1.2508e+04  2.62e-02  7.08e-07  3.31e-04  8.67e-01  2.47e-06  6.30e-01  \n",
      " 17  -1.2560e+04  -1.2685e+04  9.98e-03  2.80e-07  1.26e-04  3.35e-01  9.71e-07  7.13e-01  \n",
      " 18  -1.2630e+04  -1.2698e+04  5.37e-03  1.52e-07  6.83e-05  1.79e-01  5.27e-07  6.63e-01  \n",
      " 19  -1.2727e+04  -1.2748e+04  1.71e-03  4.88e-08  2.17e-05  5.69e-02  1.69e-07  7.82e-01  \n",
      " 20  -1.2754e+04  -1.2761e+04  5.89e-04  1.69e-08  7.47e-06  1.93e-02  5.84e-08  7.80e-01  \n",
      " 21  -1.2768e+04  -1.2770e+04  1.43e-04  4.10e-09  1.81e-06  4.66e-03  1.42e-08  8.11e-01  \n",
      " 22  -1.2771e+04  -1.2772e+04  2.08e-05  5.97e-10  2.64e-07  6.71e-04  2.07e-09  9.23e-01  \n",
      " 23  -1.2772e+04  -1.2772e+04  2.97e-06  8.53e-11  3.76e-08  9.57e-05  2.95e-10  8.68e-01  \n",
      " 24  -1.2772e+04  -1.2772e+04  2.11e-07  6.06e-12  2.67e-09  6.73e-06  2.10e-11  9.80e-01  \n",
      " 25  -1.2772e+04  -1.2772e+04  5.86e-09  1.69e-13  7.41e-11  1.86e-07  5.81e-13  9.80e-01  \n",
      "---------------------------------------------------------------------------------------------\n",
      "Terminated with status = Solved\n",
      "solve time = 32.586ms\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:18:29 AM: Problem status: optimal\n",
      "(CVXPY) Jan 04 03:18:29 AM: Optimal value: -1.277e+04\n",
      "(CVXPY) Jan 04 03:18:29 AM: Compilation took 1.795e-02 seconds\n",
      "(CVXPY) Jan 04 03:18:29 AM: Solver (including time spent in interface) took 3.690e-02 seconds\n",
      "CVXPY solution time (N=30): 0.0638 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_4880\\1185109395.py:50: RuntimeWarning: overflow encountered in square\n",
      "  v_new = (v_tilde + np.sqrt(v_tilde**2 + 4 * alpha * tau2)) / 2\n",
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_4880\\1185109395.py:45: RuntimeWarning: invalid value encountered in subtract\n",
      "  w_tilde = w - tau1 * t * Q.T @ (Q @ w - v - lam / t)\n",
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_4880\\1185109395.py:49: RuntimeWarning: invalid value encountered in multiply\n",
      "  v_tilde = (1 - tau2 * t) * v + tau2 * t * Q @ w_new - tau2 * lam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMM solution time (N=30): 0.7891 seconds\n",
      "ADMM solution time (N=100): 6.3882 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import cvxpy as cp\n",
    "import time\n",
    "\n",
    "# Problem setup for Graph Learning\n",
    "np.random.seed(0)\n",
    "N = 30  # Number of vertices (changeable for testing)\n",
    "m = int(N * (N - 1) / 2)  # Number of upper triangular elements in W\n",
    "Z = np.random.randn(N, N)\n",
    "Z = (Z + Z.T) / 2  # Symmetric matrix\n",
    "alpha, beta = 0.1, 0.01\n",
    "\n",
    "# Flatten upper triangular part of Z excluding diagonal\n",
    "def extract_upper_triangular(Z):\n",
    "    return Z[np.triu_indices_from(Z, k=1)]\n",
    "\n",
    "z = extract_upper_triangular(Z)\n",
    "\n",
    "# Part 1: Solve using CVXPY\n",
    "start_time = time.time()\n",
    "w = cp.Variable(m)\n",
    "Q = np.random.rand(N, m)  # Sparse binary matrix with Qw = W1\n",
    "loss = 2 * z.T @ w - alpha * cp.sum(cp.log(Q @ w)) + beta * cp.norm(w, 2)**2\n",
    "constraints = [w >= 0]\n",
    "problem = cp.Problem(cp.Minimize(loss), constraints)\n",
    "problem.solve(verbose=True)\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"CVXPY solution time (N={N}): {cvxpy_time:.4f} seconds\")\n",
    "\n",
    "# Part 2: ADMM Algorithm\n",
    "\n",
    "def admm_graph_learning(z, Q, alpha, beta, rho, max_iters=1000, tol=1e-6):\n",
    "    m = len(z)\n",
    "    s = Q.shape[0]\n",
    "    w = np.zeros(m)\n",
    "    v = np.ones(s)\n",
    "    lam = np.zeros(s)\n",
    "    t = 1  # Step size\n",
    "    tau1 = 1 / (2 * (N - 1) * t)\n",
    "    tau2 = 1 / t\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        # Update w\n",
    "        w_tilde = w - tau1 * t * Q.T @ (Q @ w - v - lam / t)\n",
    "        w_new = np.maximum(w_tilde - 2 * tau1 * z / (2 * tau1 * beta + 1), 0)\n",
    "\n",
    "        # Update v\n",
    "        v_tilde = (1 - tau2 * t) * v + tau2 * t * Q @ w_new - tau2 * lam\n",
    "        v_new = (v_tilde + np.sqrt(v_tilde**2 + 4 * alpha * tau2)) / 2\n",
    "\n",
    "        # Update lambda\n",
    "        lam += t * (Q @ w_new - v_new)\n",
    "\n",
    "        # Check convergence\n",
    "        rp = np.linalg.norm(t * Q.T @ (v_new - v), ord=2)\n",
    "        rd = np.linalg.norm(Q @ w_new - v_new, ord=2)\n",
    "        if rp < tol and rd < tol:\n",
    "            break\n",
    "\n",
    "        w, v = w_new, v_new\n",
    "\n",
    "    return w\n",
    "\n",
    "# Evaluate ADMM for N=30 and N=100\n",
    "for N in [30, 100]:\n",
    "    m = int(N * (N - 1) / 2)\n",
    "    Q = np.random.rand(N, m)  # Generate sparse binary matrix Q\n",
    "    Z = np.random.randn(N, N)\n",
    "    Z = (Z + Z.T) / 2  # Ensure Z is symmetric\n",
    "    z = extract_upper_triangular(Z)\n",
    "    start_time = time.time()\n",
    "    w_admm = admm_graph_learning(z, Q, alpha, beta, rho=1.0)\n",
    "    admm_time = time.time() - start_time\n",
    "    print(f\"ADMM solution time (N={N}): {admm_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.6.0                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jan 04 03:19:50 AM: Your problem has 435 variables, 435 constraints, and 0 parameters.\n",
      "(CVXPY) Jan 04 03:19:50 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jan 04 03:19:50 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jan 04 03:19:50 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Jan 04 03:19:50 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:19:50 AM: Compiling problem (target solver=CLARABEL).\n",
      "(CVXPY) Jan 04 03:19:50 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n",
      "(CVXPY) Jan 04 03:19:50 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jan 04 03:19:50 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jan 04 03:19:50 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jan 04 03:19:50 AM: Applying reduction CLARABEL\n",
      "(CVXPY) Jan 04 03:19:50 AM: Finished problem compilation (took 1.664e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:19:50 AM: Invoking solver CLARABEL  to obtain a solution.\n",
      "-------------------------------------------------------------\n",
      "           Clarabel.rs v0.9.0  -  Clever Acronym                \n",
      "\n",
      "                   (c) Paul Goulart                          \n",
      "                University of Oxford, 2022                   \n",
      "-------------------------------------------------------------\n",
      "\n",
      "problem:\n",
      "  variables     = 466\n",
      "  constraints   = 961\n",
      "  nnz(P)        = 1\n",
      "  nnz(A)        = 13951\n",
      "  cones (total) = 32\n",
      "    : Nonnegative = 1,  numel = 435\n",
      "    : SecondOrder = 1,  numel = 436\n",
      "    : Exponential = 30,  numel = (3,3,3,3,...,3)\n",
      "\n",
      "settings:\n",
      "  linear algebra: direct / qdldl, precision: 64 bit\n",
      "  max iter = 200, time limit = Inf,  max step = 0.990\n",
      "  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n",
      "  static reg : on, ϵ1 = 1.0e-8, ϵ2 = 4.9e-32\n",
      "  dynamic reg: on, ϵ = 1.0e-13, δ = 2.0e-7\n",
      "  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n",
      "               max iter = 10, stop ratio = 5.0\n",
      "  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n",
      "               max iter = 10\n",
      "\n",
      "iter    pcost        dcost       gap       pres      dres      k/t        μ       step      \n",
      "---------------------------------------------------------------------------------------------\n",
      "  0  +0.0000e+00  -9.2966e+01  9.30e+01  9.85e-01  9.09e+00  1.00e+00  1.00e+00   ------   \n",
      "  1  -2.1585e-01  -8.7864e+01  8.76e+01  7.87e-01  3.18e+00  2.54e+00  3.61e-01  7.64e-01  \n",
      "  2  -9.1473e-01  -7.3685e+01  7.28e+01  5.55e-01  1.60e+00  4.10e+00  1.59e-01  6.34e-01  \n",
      "  3  -4.1373e+00  -5.2033e+01  1.16e+01  2.24e-01  1.94e+00  1.90e+00  1.07e-01  5.48e-01  \n",
      "  4  -7.9725e+00  -3.7805e+01  3.74e+00  1.01e-01  1.21e+00  1.33e+00  5.27e-02  6.33e-01  \n",
      "  5  -2.0540e+01  -3.5784e+01  7.42e-01  3.08e-02  4.88e-01  7.81e-01  1.85e-02  7.29e-01  \n",
      "  6  -3.8315e+01  -6.0056e+01  5.67e-01  7.60e-03  1.36e-01  7.31e-01  5.66e-03  9.80e-01  \n",
      "  7  -5.0729e+01  -6.1047e+01  2.03e-01  1.55e-03  2.94e-02  2.46e-01  1.38e-03  8.08e-01  \n",
      "  8  -5.6002e+01  -6.0661e+01  8.32e-02  6.27e-04  1.19e-02  1.29e-01  6.03e-04  9.80e-01  \n",
      "  9  -6.0600e+01  -6.1896e+01  2.14e-02  1.62e-04  3.07e-03  3.57e-02  1.67e-04  7.98e-01  \n",
      " 10  -6.1424e+01  -6.1879e+01  7.40e-03  5.65e-05  1.07e-03  1.20e-02  5.88e-05  8.38e-01  \n",
      " 11  -6.2020e+01  -6.2105e+01  1.38e-03  1.04e-05  1.97e-04  2.20e-03  1.11e-05  8.64e-01  \n",
      " 12  -6.2112e+01  -6.2127e+01  2.37e-04  1.78e-06  3.38e-05  3.66e-04  1.90e-06  9.05e-01  \n",
      " 13  -6.2134e+01  -6.2135e+01  2.40e-05  1.81e-07  3.42e-06  3.70e-05  1.93e-07  9.06e-01  \n",
      " 14  -6.2136e+01  -6.2136e+01  2.34e-06  1.76e-08  3.33e-07  3.50e-06  1.88e-08  9.65e-01  \n",
      " 15  -6.2136e+01  -6.2136e+01  1.05e-07  7.93e-10  1.50e-08  1.57e-07  8.47e-10  9.63e-01  \n",
      " 16  -6.2136e+01  -6.2136e+01  2.52e-08  1.89e-10  3.59e-09  3.75e-08  2.02e-10  7.92e-01  \n",
      " 17  -6.2136e+01  -6.2136e+01  5.41e-09  4.07e-11  7.71e-10  8.06e-09  4.35e-11  7.92e-01  \n",
      "---------------------------------------------------------------------------------------------\n",
      "Terminated with status = Solved\n",
      "solve time = 22.1279ms\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:19:50 AM: Problem status: optimal\n",
      "(CVXPY) Jan 04 03:19:50 AM: Optimal value: -6.214e+01\n",
      "(CVXPY) Jan 04 03:19:50 AM: Compilation took 1.664e-02 seconds\n",
      "(CVXPY) Jan 04 03:19:50 AM: Solver (including time spent in interface) took 2.493e-02 seconds\n",
      "CVXPY solution time (N=30): 0.0565 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Password Please\\AppData\\Local\\Temp\\ipykernel_4880\\2511696383.py:54: RuntimeWarning: overflow encountered in square\n",
      "  v_tilde_squared = np.clip(v_tilde**2, a_min=0, a_max=1e6)  # Clip to prevent overflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMM solution time (N=30): 0.8902 seconds\n",
      "ADMM solution time (N=100): 7.3441 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import cvxpy as cp\n",
    "import time\n",
    "\n",
    "# Problem setup for Graph Learning\n",
    "np.random.seed(0)\n",
    "N = 30  # Number of vertices (changeable for testing)\n",
    "m = int(N * (N - 1) / 2)  # Number of upper triangular elements in W\n",
    "Z = np.random.randn(N, N)\n",
    "Z = (Z + Z.T) / 2  # Symmetric matrix\n",
    "alpha, beta = 0.1, 0.01\n",
    "\n",
    "# Flatten upper triangular part of Z excluding diagonal\n",
    "def extract_upper_triangular(Z):\n",
    "    return Z[np.triu_indices_from(Z, k=1)]\n",
    "\n",
    "z = extract_upper_triangular(Z)\n",
    "\n",
    "# Normalize z to prevent overflow\n",
    "z = z / np.linalg.norm(z, ord=2)\n",
    "\n",
    "# Part 1: Solve using CVXPY\n",
    "start_time = time.time()\n",
    "w = cp.Variable(m)\n",
    "Q = np.random.rand(N, m)  # Sparse binary matrix with Qw = W1\n",
    "Q = Q / np.linalg.norm(Q, ord=2)  # Normalize Q to prevent overflow\n",
    "loss = 2 * z.T @ w - alpha * cp.sum(cp.log(Q @ w)) + beta * cp.norm(w, 2)**2\n",
    "constraints = [w >= 0]\n",
    "problem = cp.Problem(cp.Minimize(loss), constraints)\n",
    "problem.solve(verbose=True)\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"CVXPY solution time (N={N}): {cvxpy_time:.4f} seconds\")\n",
    "\n",
    "# Part 2: ADMM Algorithm\n",
    "\n",
    "def admm_graph_learning(z, Q, alpha, beta, rho, max_iters=1000, tol=1e-6):\n",
    "    m = len(z)\n",
    "    s = Q.shape[0]\n",
    "    w = np.zeros(m)\n",
    "    v = np.ones(s)\n",
    "    lam = np.zeros(s)\n",
    "    t = 0.1  # Reduced step size for stability\n",
    "    tau1 = 1 / (2 * (N - 1) * t)\n",
    "    tau2 = 1 / t\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        # Update w\n",
    "        w_tilde = w - tau1 * t * Q.T @ (Q @ w - v - lam / t)\n",
    "        w_new = np.maximum(w_tilde - 2 * tau1 * z / (2 * tau1 * beta + 1), 0)\n",
    "\n",
    "        # Update v\n",
    "        v_tilde = (1 - tau2 * t) * v + tau2 * t * Q @ w_new - tau2 * lam\n",
    "        v_tilde_squared = np.clip(v_tilde**2, a_min=0, a_max=1e6)  # Clip to prevent overflow\n",
    "        v_new = (v_tilde + np.sqrt(v_tilde_squared + 4 * alpha * tau2)) / 2\n",
    "\n",
    "        # Update lambda\n",
    "        lam += t * (Q @ w_new - v_new)\n",
    "\n",
    "        # Check convergence\n",
    "        rp = np.linalg.norm(t * Q.T @ (v_new - v), ord=2)\n",
    "        rd = np.linalg.norm(Q @ w_new - v_new, ord=2)\n",
    "        if rp < tol and rd < tol:\n",
    "            break\n",
    "\n",
    "        if np.any(np.isnan(w_new)) or np.any(np.isinf(w_new)) or np.any(np.isnan(v_new)) or np.any(np.isinf(v_new)):\n",
    "            print(\"Numerical instability detected. Stopping iteration.\")\n",
    "            break\n",
    "\n",
    "        w, v = w_new, v_new\n",
    "\n",
    "    return w\n",
    "\n",
    "# Evaluate ADMM for N=30 and N=100\n",
    "for N in [30, 100]:\n",
    "    m = int(N * (N - 1) / 2)\n",
    "    Q = np.random.rand(N, m)  # Generate sparse binary matrix Q\n",
    "    Q = Q / np.linalg.norm(Q, ord=2)  # Normalize Q to prevent overflow\n",
    "    Z = np.random.randn(N, N)\n",
    "    Z = (Z + Z.T) / 2  # Ensure Z is symmetric\n",
    "    z = extract_upper_triangular(Z)\n",
    "    z = z / np.linalg.norm(z, ord=2)  # Normalize z to prevent overflow\n",
    "    start_time = time.time()\n",
    "    w_admm = admm_graph_learning(z, Q, alpha, beta, rho=1.0)\n",
    "    admm_time = time.time() - start_time\n",
    "    print(f\"ADMM solution time (N={N}): {admm_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.6.0                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jan 04 03:20:54 AM: Your problem has 435 variables, 435 constraints, and 0 parameters.\n",
      "(CVXPY) Jan 04 03:20:54 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jan 04 03:20:54 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jan 04 03:20:54 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Jan 04 03:20:54 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:20:54 AM: Compiling problem (target solver=CLARABEL).\n",
      "(CVXPY) Jan 04 03:20:54 AM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CLARABEL\n",
      "(CVXPY) Jan 04 03:20:54 AM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Jan 04 03:20:54 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jan 04 03:20:54 AM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jan 04 03:20:54 AM: Applying reduction CLARABEL\n",
      "(CVXPY) Jan 04 03:20:54 AM: Finished problem compilation (took 1.695e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:20:54 AM: Invoking solver CLARABEL  to obtain a solution.\n",
      "-------------------------------------------------------------\n",
      "           Clarabel.rs v0.9.0  -  Clever Acronym                \n",
      "\n",
      "                   (c) Paul Goulart                          \n",
      "                University of Oxford, 2022                   \n",
      "-------------------------------------------------------------\n",
      "\n",
      "problem:\n",
      "  variables     = 466\n",
      "  constraints   = 961\n",
      "  nnz(P)        = 1\n",
      "  nnz(A)        = 13951\n",
      "  cones (total) = 32\n",
      "    : Nonnegative = 1,  numel = 435\n",
      "    : SecondOrder = 1,  numel = 436\n",
      "    : Exponential = 30,  numel = (3,3,3,3,...,3)\n",
      "\n",
      "settings:\n",
      "  linear algebra: direct / qdldl, precision: 64 bit\n",
      "  max iter = 200, time limit = Inf,  max step = 0.990\n",
      "  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n",
      "  static reg : on, ϵ1 = 1.0e-8, ϵ2 = 4.9e-32\n",
      "  dynamic reg: on, ϵ = 1.0e-13, δ = 2.0e-7\n",
      "  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n",
      "               max iter = 10, stop ratio = 5.0\n",
      "  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n",
      "               max iter = 10\n",
      "\n",
      "iter    pcost        dcost       gap       pres      dres      k/t        μ       step      \n",
      "---------------------------------------------------------------------------------------------\n",
      "  0  +0.0000e+00  -9.2966e+01  9.30e+01  9.85e-01  9.09e+00  1.00e+00  1.00e+00   ------   \n",
      "  1  -2.1585e-01  -8.7865e+01  8.76e+01  7.87e-01  3.18e+00  2.54e+00  3.61e-01  7.64e-01  \n",
      "  2  -9.1473e-01  -7.3685e+01  7.28e+01  5.55e-01  1.60e+00  4.10e+00  1.59e-01  6.34e-01  \n",
      "  3  -4.1373e+00  -5.2033e+01  1.16e+01  2.24e-01  1.94e+00  1.90e+00  1.07e-01  5.48e-01  \n",
      "  4  -7.9725e+00  -3.7805e+01  3.74e+00  1.01e-01  1.21e+00  1.33e+00  5.27e-02  6.33e-01  \n",
      "  5  -2.0540e+01  -3.5784e+01  7.42e-01  3.08e-02  4.88e-01  7.81e-01  1.85e-02  7.29e-01  \n",
      "  6  -3.8315e+01  -6.0056e+01  5.67e-01  7.60e-03  1.36e-01  7.31e-01  5.66e-03  9.80e-01  \n",
      "  7  -5.0729e+01  -6.1047e+01  2.03e-01  1.55e-03  2.94e-02  2.46e-01  1.38e-03  8.08e-01  \n",
      "  8  -5.6002e+01  -6.0661e+01  8.32e-02  6.27e-04  1.19e-02  1.29e-01  6.03e-04  9.80e-01  \n",
      "  9  -6.0600e+01  -6.1896e+01  2.14e-02  1.62e-04  3.07e-03  3.57e-02  1.67e-04  7.98e-01  \n",
      " 10  -6.1424e+01  -6.1879e+01  7.40e-03  5.65e-05  1.07e-03  1.20e-02  5.89e-05  8.38e-01  \n",
      " 11  -6.2020e+01  -6.2105e+01  1.38e-03  1.04e-05  1.97e-04  2.20e-03  1.11e-05  8.64e-01  \n",
      " 12  -6.2112e+01  -6.2127e+01  2.37e-04  1.78e-06  3.38e-05  3.66e-04  1.90e-06  9.05e-01  \n",
      " 13  -6.2134e+01  -6.2135e+01  2.40e-05  1.81e-07  3.42e-06  3.70e-05  1.93e-07  9.06e-01  \n",
      " 14  -6.2136e+01  -6.2136e+01  2.34e-06  1.76e-08  3.33e-07  3.50e-06  1.88e-08  9.65e-01  \n",
      " 15  -6.2136e+01  -6.2136e+01  1.05e-07  7.93e-10  1.50e-08  1.57e-07  8.47e-10  9.63e-01  \n",
      " 16  -6.2136e+01  -6.2136e+01  4.17e-08  3.14e-10  5.95e-09  6.22e-08  3.35e-10  6.34e-01  \n",
      " 17  -6.2136e+01  -6.2136e+01  2.30e-08  1.73e-10  3.28e-09  3.43e-08  1.85e-10  5.07e-01  \n",
      " 18  -6.2136e+01  -6.2136e+01  4.94e-09  3.71e-11  7.04e-10  7.35e-09  3.97e-11  7.92e-01  \n",
      "---------------------------------------------------------------------------------------------\n",
      "Terminated with status = Solved\n",
      "solve time = 22.9324ms\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jan 04 03:20:54 AM: Problem status: optimal\n",
      "(CVXPY) Jan 04 03:20:54 AM: Optimal value: -6.214e+01\n",
      "(CVXPY) Jan 04 03:20:54 AM: Compilation took 1.695e-02 seconds\n",
      "(CVXPY) Jan 04 03:20:54 AM: Solver (including time spent in interface) took 2.693e-02 seconds\n",
      "CVXPY solution time (N=30): 0.0578 seconds\n",
      "ADMM solution time (N=30): 0.8149 seconds\n",
      "ADMM solution time (N=100): 7.0736 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import cvxpy as cp\n",
    "import time\n",
    "\n",
    "# Problem setup for Graph Learning\n",
    "np.random.seed(0)\n",
    "N = 30  # Number of vertices (changeable for testing)\n",
    "m = int(N * (N - 1) / 2)  # Number of upper triangular elements in W\n",
    "Z = np.random.randn(N, N)\n",
    "Z = (Z + Z.T) / 2  # Symmetric matrix\n",
    "alpha, beta = 0.1, 0.01\n",
    "\n",
    "# Flatten upper triangular part of Z excluding diagonal\n",
    "def extract_upper_triangular(Z):\n",
    "    return Z[np.triu_indices_from(Z, k=1)]\n",
    "\n",
    "z = extract_upper_triangular(Z)\n",
    "\n",
    "# Normalize z to prevent overflow\n",
    "z = z / np.linalg.norm(z, ord=2)\n",
    "\n",
    "# Part 1: Solve using CVXPY\n",
    "start_time = time.time()\n",
    "w = cp.Variable(m)\n",
    "Q = np.random.rand(N, m)  # Sparse binary matrix with Qw = W1\n",
    "Q = Q / np.linalg.norm(Q, ord=2)  # Normalize Q to prevent overflow\n",
    "loss = 2 * z.T @ w - alpha * cp.sum(cp.log(Q @ w + 1e-6)) + beta * cp.norm(w, 2)**2  # Add small constant to avoid log(0)\n",
    "constraints = [w >= 0]\n",
    "problem = cp.Problem(cp.Minimize(loss), constraints)\n",
    "problem.solve(verbose=True)\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"CVXPY solution time (N={N}): {cvxpy_time:.4f} seconds\")\n",
    "\n",
    "# Part 2: ADMM Algorithm\n",
    "\n",
    "def admm_graph_learning(z, Q, alpha, beta, rho, max_iters=1000, tol=1e-6):\n",
    "    m = len(z)\n",
    "    s = Q.shape[0]\n",
    "    w = np.zeros(m)\n",
    "    v = np.ones(s)\n",
    "    lam = np.zeros(s)\n",
    "    t = 0.1  # Reduced step size for stability\n",
    "    tau1 = 1 / (2 * (N - 1) * t)\n",
    "    tau2 = 1 / t\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        # Update w\n",
    "        w_tilde = w - tau1 * t * Q.T @ (Q @ w - v - lam / t)\n",
    "        w_new = np.maximum(w_tilde - 2 * tau1 * z / (2 * tau1 * beta + 1), 0)\n",
    "\n",
    "        # Update v\n",
    "        v_tilde = (1 - tau2 * t) * v + tau2 * t * Q @ w_new - tau2 * lam\n",
    "        v_tilde = np.clip(v_tilde, a_min=-1e3, a_max=1e3)  # Clip directly to prevent overflow\n",
    "        v_tilde_squared = v_tilde**2\n",
    "        v_new = (v_tilde + np.sqrt(v_tilde_squared + 4 * alpha * tau2)) / 2\n",
    "\n",
    "        # Update lambda\n",
    "        lam += t * (Q @ w_new - v_new)\n",
    "\n",
    "        # Check convergence\n",
    "        rp = np.linalg.norm(t * Q.T @ (v_new - v), ord=2)\n",
    "        rd = np.linalg.norm(Q @ w_new - v_new, ord=2)\n",
    "        if rp < tol and rd < tol:\n",
    "            break\n",
    "\n",
    "        if np.any(np.isnan(w_new)) or np.any(np.isinf(w_new)) or np.any(np.isnan(v_new)) or np.any(np.isinf(v_new)):\n",
    "            print(\"Numerical instability detected. Stopping iteration.\")\n",
    "            break\n",
    "\n",
    "        w, v = w_new, v_new\n",
    "\n",
    "    return w\n",
    "\n",
    "# Evaluate ADMM for N=30 and N=100\n",
    "for N in [30, 100]:\n",
    "    m = int(N * (N - 1) / 2)\n",
    "    Q = np.random.rand(N, m)  # Generate sparse binary matrix Q\n",
    "    Q = Q / np.linalg.norm(Q, ord=2)  # Normalize Q to prevent overflow\n",
    "    Z = np.random.randn(N, N)\n",
    "    Z = (Z + Z.T) / 2  # Ensure Z is symmetric\n",
    "    z = extract_upper_triangular(Z)\n",
    "    z = z / np.linalg.norm(z, ord=2)  # Normalize z to prevent overflow\n",
    "    start_time = time.time()\n",
    "    w_admm = admm_graph_learning(z, Q, alpha, beta, rho=1.0)\n",
    "    admm_time = time.time() - start_time\n",
    "    print(f\"ADMM solution time (N={N}): {admm_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   graph_size  objective_value  time_taken_sec\n",
      "0          30        -7.479221        0.049864\n",
      "1         100       -64.834648        0.559603\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def solve_graph_learning_cvxpy(N, alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Solve the graph learning problem using CVXPY for a graph with N vertices.\n",
    "    Args:\n",
    "        N (int): Number of vertices in the graph.\n",
    "        alpha (float): Regularization parameter for the log barrier term.\n",
    "        beta (float): Regularization parameter for the Frobenius norm.\n",
    "    Returns:\n",
    "        objective_value (float): Final objective value.\n",
    "        time_taken (float): Time taken to solve the problem.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    Z = np.random.randn(N, N)  # Random observation matrix\n",
    "    Z = (Z + Z.T) / 2  # Symmetrize Z\n",
    "\n",
    "    # Define the optimization variable\n",
    "    W = cp.Variable((N, N), symmetric=True)\n",
    "\n",
    "    # Define the objective function\n",
    "    objective = cp.Minimize(cp.norm1(cp.multiply(W, Z)) - alpha * cp.sum(cp.log(W @ np.ones(N))) + (beta / 2) * cp.norm(W, 'fro')**2)\n",
    "\n",
    "    # Define the constraints\n",
    "    constraints = [W >= 0, cp.diag(W) == 0]\n",
    "\n",
    "    # Define and solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    start_time = time.time()\n",
    "    problem.solve()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return problem.value, end_time - start_time\n",
    "\n",
    "# Test the function for N = 30 and N = 100\n",
    "graph_sizes = [30, 100]\n",
    "results = []\n",
    "\n",
    "for N in graph_sizes:\n",
    "    obj_value, time_taken = solve_graph_learning_cvxpy(N)\n",
    "    results.append({\n",
    "        \"graph_size\": N,\n",
    "        \"objective_value\": obj_value,\n",
    "        \"time_taken_sec\": time_taken\n",
    "    })\n",
    "\n",
    "# Display the results in a table\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_size</th>\n",
       "      <th>objective_value</th>\n",
       "      <th>iterations</th>\n",
       "      <th>time_taken_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>414.465317</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1381.551056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   graph_size  objective_value  iterations  time_taken_sec\n",
       "0          30       414.465317           1             0.0\n",
       "1         100      1381.551056           1             0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def admm_graph_learning(N, alpha=1.0, beta=1.0, rho=1.0, max_iter=1000, tol=1e-4):\n",
    "    \"\"\"\n",
    "    ADMM algorithm for graph learning.\n",
    "    Args:\n",
    "        N (int): Number of vertices in the graph.\n",
    "        alpha (float): Regularization parameter for the log barrier term.\n",
    "        beta (float): Regularization parameter for the Frobenius norm.\n",
    "        rho (float): ADMM parameter.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "        tol (float): Tolerance for convergence criteria.\n",
    "    Returns:\n",
    "        objective_value (float): Final objective value.\n",
    "        iterations (int): Number of iterations performed.\n",
    "        time_taken (float): Time taken to solve the problem.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    Z = np.random.randn(N, N)\n",
    "    Z = (Z + Z.T) / 2  # Symmetrize Z\n",
    "\n",
    "    # Initialize variables\n",
    "    W = np.random.rand(N, N)\n",
    "    W = (W + W.T) / 2\n",
    "    np.fill_diagonal(W, 0)\n",
    "    v = np.zeros_like(W)\n",
    "    lam = np.zeros_like(W)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Update W using proximal operator (soft-thresholding and non-negativity constraint)\n",
    "        W_new = np.maximum(W - rho * (W - v - lam / rho), 0)\n",
    "        np.fill_diagonal(W_new, 0)\n",
    "        \n",
    "        # Update v using proximal operator for log barrier term\n",
    "        v_new = np.maximum(W_new + lam / rho, 1e-6)\n",
    "        np.fill_diagonal(v_new, 0)\n",
    "        \n",
    "        # Update lambda (dual variable)\n",
    "        lam_new = lam + rho * (W_new - v_new)\n",
    "        \n",
    "        # Compute residuals\n",
    "        r_p = np.linalg.norm(W_new - v_new, 'fro')\n",
    "        r_d = np.linalg.norm(v_new - v, 'fro')\n",
    "        \n",
    "        # Check convergence\n",
    "        if r_p < tol and r_d < tol:\n",
    "            break\n",
    "        \n",
    "        # Update variables for next iteration\n",
    "        W, v, lam = W_new, v_new, lam_new\n",
    "    \n",
    "    end_time = time.time()\n",
    "    objective_value = np.sum(np.abs(W_new * Z)) - alpha * np.sum(np.log(np.sum(W_new, axis=1) + 1e-6)) + (beta / 2) * np.linalg.norm(W_new, 'fro')**2\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    return objective_value, k + 1, time_taken\n",
    "\n",
    "# Test the ADMM algorithm for graph sizes N = 30 and N = 100\n",
    "graph_sizes = [30, 100]\n",
    "results = []\n",
    "\n",
    "for N in graph_sizes:\n",
    "    obj_value, iterations, time_taken = admm_graph_learning(N)\n",
    "    results.append({\n",
    "        \"graph_size\": N,\n",
    "        \"objective_value\": obj_value,\n",
    "        \"iterations\": iterations,\n",
    "        \"time_taken_sec\": time_taken\n",
    "    })\n",
    "\n",
    "# Display the results in a table\n",
    "pd.DataFrame(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
